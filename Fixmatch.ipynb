{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fixmatch.ipynb","provenance":[],"authorship_tag":"ABX9TyOAV//3+kfVlgnIZ9hoGLiB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"t0ZZPr_lprkR","executionInfo":{"status":"ok","timestamp":1602151349832,"user_tz":-180,"elapsed":4004,"user":{"displayName":"Catherine Gitau","photoUrl":"","userId":"06647096774192026420"}}},"source":["#import the necessary libaries\n","import os\n","from pathlib import Path\n","import sys\n","import pdb\n","import logging\n","import traceback\n","\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVUwz_7Jpyb_","executionInfo":{"status":"ok","timestamp":1602151353472,"user_tz":-180,"elapsed":7620,"user":{"displayName":"Catherine Gitau","photoUrl":"","userId":"06647096774192026420"}}},"source":["from functools import partial\n","\n","import fastai\n","from fastai.vision import *\n","\n","from fastai.basic_train import LearnerCallback, Learner, DataBunch, SmoothenValue, to_data, functools, \\\n","    add_metrics, Module, nn\n","from fastai.imports import torch, F\n","\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","from numbers import Integral\n","import gc\n","\n","import torchvision"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"jiX7K475p2_3","executionInfo":{"status":"ok","timestamp":1602151353474,"user_tz":-180,"elapsed":7613,"user":{"displayName":"Catherine Gitau","photoUrl":"","userId":"06647096774192026420"}}},"source":["class MultiTfmLabelList(LabelList):\n","    def __init__(self, x:ItemList, y:ItemList, tfms:TfmList=None, tfm_y:bool=False, K=2, **kwargs):\n","        \"K: number of transformed samples generated per item\"\n","        self.x,self.y,self.tfm_y,self.K = x,y,tfm_y,K\n","        self.y.x = x\n","        self.item=None\n","        self.transform(tfms, **kwargs)\n","        \n","    def __getitem__(self,idxs:Union[int, np.ndarray])->'LabelList':\n","        \"return a single (x, y) if `idxs` is an integer or a new `LabelList` object if `idxs` is a range.\"\n","        idxs = try_int(idxs)\n","        if isinstance(idxs, Integral):\n","            if self.item is None: x,y = self.x[idxs],self.y[idxs]\n","            else:                 x,y = self.item   ,0\n","            if self.tfms or self.tfmargs:\n","                x = [x.apply_tfms(self.tfms, **self.tfmargs) for _ in range(self.K)]\n","            if hasattr(self, 'tfms_y') and self.tfm_y and self.item is None:\n","                y = y.apply_tfms(self.tfms_y, **{**self.tfmargs_y, 'do_resolve':False})\n","            if y is None: y=0\n","            return x,y\n","        else: return self.new(self.x[idxs], self.y[idxs])\n","\n","def MultiCollate(batch):\n","    batch = to_data(batch)\n","    if isinstance(batch[0][0],list): batch = [[torch.stack(s[0]),s[1]] for s in batch]\n","    return torch.utils.data.dataloader.default_collate(batch)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"FrCEfht0p5nm","executionInfo":{"status":"ok","timestamp":1602151353476,"user_tz":-180,"elapsed":7598,"user":{"displayName":"Catherine Gitau","photoUrl":"","userId":"06647096774192026420"}}},"source":["class FixMatchLoss(Module):\n","\n","    def __init__(self, reduction='mean', unlabeled_loss_coeff=1.0, threshold=0.95):\n","        super().__init__()\n","        crit = nn.CrossEntropyLoss()\n","        if hasattr(crit, 'reduction'):\n","            self.crit = crit\n","            self.old_red = crit.reduction\n","            setattr(self.crit, 'reduction', 'none')\n","        else:\n","            self.crit = partial(crit, reduction='none')\n","            self.old_crit = crit\n","        self.reduction = reduction\n","        self.unlabeled_loss_coeff = unlabeled_loss_coeff\n","        self.threshold = threshold\n","\n","    def forward(self, preds, target, bs=None):\n","\n","        if bs is None: return F.cross_entropy(preds, target)\n","\n","        # labeled_preds = torch.log_softmax(preds[:bs], dim=1)       \n","        # Lx = -(labeled_preds * target[:bs]).sum(dim=1).mean()\n","        # Lx = -(labeled_preds[range(labeled_preds.shape[0]), target[:bs]]).mean()\n","        \n","        Lx = F.cross_entropy(preds[:bs], target[:bs])\n","        self.Lx = Lx.item()\n","\n","        logits_u_w, logits_u_s = preds[bs:].chunk(2)\n","\n","        pseudo_label = torch.softmax(logits_u_w.detach_(), dim=-1)\n","        max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n","        mask = max_probs.ge(self.threshold).float()\n","\n","        Lu = (F.cross_entropy(logits_u_s, targets_u, reduction='none') * mask).mean()\n","\n","        self.Lu = (Lu * self.unlabeled_loss_coeff).item()\n","\n","        return Lx + Lu * self.unlabeled_loss_coeff\n","\n","    def get_old(self):\n","        if hasattr(self, 'old_crit'):\n","            return self.old_crit\n","        elif hasattr(self, 'old_red'):\n","            setattr(self.crit, 'reduction', self.old_red)\n","            return self.crit\n","\n","\n","class FixMatchCallback(LearnerCallback):\n","    _order = -20\n","\n","    def __init__(self,\n","                 learn: Learner,\n","                 unlabeled_data: DataBunch,\n","                 unlabeled_loss_coeff: float = 1):\n","        super().__init__(learn)\n","\n","        self.learn, self.unlabeled_loss_coeff = learn, unlabeled_loss_coeff\n","        self.unlabeled_dl = unlabeled_data.train_dl\n","        self.n_classes = unlabeled_data.c\n","        self.unlabeled_data = unlabeled_data\n","\n","    def on_train_begin(self, n_epochs, **kwargs):\n","        self.learn.loss_func = FixMatchLoss(unlabeled_loss_coeff=self.unlabeled_loss_coeff)\n","        self.uldliter = iter(self.unlabeled_dl)\n","        self.smoothLx, self.smoothLu = SmoothenValue(0.98), SmoothenValue(0.98)\n","        self.recorder.add_metric_names([\"train_Lx\", \"train_Lu*Î»\"])\n","        self.it = 0\n","        print('labeled dataset     : {:13,} samples'.format(len(self.learn.data.train_ds)))\n","        print('unlabeled dataset   : {:13,} samples'.format(len(self.unlabeled_data.train_ds)))\n","        print(\"labeled batch size:\", learn.data.batch_size)\n","        print(\"unlabeled batch size:\", unlabeled_data.batch_size)\n","        # total_samples = n_epochs * len(self.learn.data.train_dl) * \\\n","        #                 self.learn.data.train_dl.batch_size * (self.label_list.K + 1)\n","        # print('total train samples : {:13,} samples'.format(total_samples))\n","\n","    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n","        # Augmentation should already be applied in dataloader\n","        if not train: return\n","\n","        ## UNLABELED\n","        try:\n","            # (inputs_u_w, inputs_u_s), _ = next(self.uldliter)\n","            # (batch_size, n_img, channel, height x width)\n","            \n","            img_pairs, _labels = next(self.uldliter)\n","            weak_imgs, strong_imgs = torch.split(img_pairs, 1, dim=1)\n","            inputs_u_w = weak_imgs.squeeze()\n","            inputs_u_s = strong_imgs.squeeze()\n","\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        except StopIteration as exc:\n","            self.uldliter = iter(self.unlabeled_dl)\n","\n","            # (inputs_u_w, inputs_u_s), _ = next(self.uldliter)\n","\n","            img_pairs, _labels = next(self.uldliter)\n","            weak_imgs, strong_imgs = torch.split(img_pairs, 1, dim=1)\n","            inputs_u_w = weak_imgs.squeeze()\n","            inputs_u_s = strong_imgs.squeeze()\n","\n","        bs = len(last_input)\n","\n","        # LABELED\n","        inputs = torch.cat((last_input, inputs_u_w, inputs_u_s))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        \n","        return {\"last_input\": inputs, \"last_target\": (last_target, bs)}\n","\n","    def on_batch_end(self, train, **kwargs):\n","        if not train: return\n","        self.smoothLx.add_value(self.learn.loss_func.Lx)\n","        self.smoothLu.add_value(self.learn.loss_func.Lu)\n","        self.it += 1\n","\n","    def on_epoch_end(self, last_metrics, **kwargs):\n","        return add_metrics(last_metrics, [self.smoothLx.smooth, self.smoothLu.smooth])\n","\n","    def on_train_end(self, **kwargs):\n","        \"\"\"At the end of training, loss_func and data are returned to their original values,\n","        and this calleback is removed\"\"\"\n","        self.learn.loss_func = self.learn.loss_func.get_old()\n","        drop_cb_fn(self.learn, 'FixMatchCallback')\n","\n","\n","def drop_cb_fn(learn, cb_name: str) -> None:\n","    cbs = []\n","    for cb in learn.callback_fns:\n","        if isinstance(cb, functools.partial):\n","            cbn = cb.func.__name__\n","        else:\n","            cbn = cb.__name__\n","        if cbn != cb_name: cbs.append(cb)\n","    learn.callback_fns = cbs\n","\n","\n","def fixmatch(learn: Learner, u_databunch: DataBunch, num_workers: int = None, unlabeled_loss_coeff: float = 1) -> Learner:\n","    labeled_data = learn.data\n","    learn.unlabeled_data = u_databunch\n","    if num_workers is None: num_workers = 1\n","    labeled_data.train_dl.num_workers = num_workers\n","    bs = labeled_data.train_dl.batch_size\n","    learn.callback_fns.append(partial(FixMatchCallback, unlabeled_data=u_databunch, unlabeled_loss_coeff=unlabeled_loss_coeff))\n","    return learn\n","\n","Learner.fixmatch = fixmatch"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzyUgaMYp742","executionInfo":{"status":"ok","timestamp":1602151353477,"user_tz":-180,"elapsed":7594,"user":{"displayName":"Catherine Gitau","photoUrl":"","userId":"06647096774192026420"}}},"source":["class MultiTfmPairLabelList(LabelList):\n","    def __init__(self, x:ItemList, y:ItemList, \n","                 weak_tfms:TfmList=None, strong_tfms:TfmList=None, extra_weak_tfms=None, extra_strong_tfms=None, tfm_y:bool=False, \n","                 K=2, **kwargs):\n","        \"K: number of transformed samples generated per item\"\n","        self.x,self.y,self.tfm_y,self.K = x,y,tfm_y,K\n","        self.y.x = x\n","        self.item=None\n","        # self.transform(tfms, **kwargs)\n","        self.weak_tfms, self.strong_tfms = weak_tfms, strong_tfms\n","        self.extra_weak_tfms, self.extra_strong_tfms = extra_weak_tfms, extra_strong_tfms\n","        \n","    def __getitem__(self,idxs:Union[int, np.ndarray])->'LabelList':\n","        \"return a single (x, y) if `idxs` is an integer or a new `LabelList` object if `idxs` is a range.\"\n","        idxs = try_int(idxs)\n","        if isinstance(idxs, Integral):\n","            if self.item is None: x,y = self.x[idxs],self.y[idxs]\n","            else:                 x,y = self.item   ,0\n","            if self.weak_tfms and self.strong_tfms:\n","                # x = [x.apply_tfms(self.tfms, **self.tfmargs) for _ in range(self.K)]\n","                # x = [x.apply_tfms(self.weak_tfms), x.apply_tfms(self.strong_tfms)]\n","                x = (\n","                      x.apply_tfms(self.weak_tfms, size=128, resize_method=ResizeMethod.SQUISH), \n","                      x.apply_tfms(self.strong_tfms, size=128, resize_method=ResizeMethod.SQUISH))\n","            if self.extra_weak_tfms:\n","                x = (self.extra_weak_tfms(x[0].data), x[1])\n","            if self.extra_strong_tfms:\n","                x = (x[0], self.extra_strong_tfms(x[1].data))\n","\n","            if hasattr(self, 'tfms_y') and self.tfm_y and self.item is None:\n","                y = y.apply_tfms(self.tfms_y, **{**self.tfmargs_y, 'do_resolve':False})\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","            if y is None: y=0\n","            return x,y\n","        else: return self.new(self.x[idxs], self.y[idxs])\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBbJeu5jqBrt","executionInfo":{"status":"ok","timestamp":1602151353478,"user_tz":-180,"elapsed":7591,"user":{"displayName":"Catherine Gitau","photoUrl":"","userId":"06647096774192026420"}}},"source":["#get weak transforms\n","def get_weak_transforms():\n","  weak_transforms = get_transforms()[0]\n","  return weak_transforms\n","\n","def get_strong_transforms():\n","  strong_transforms = get_transforms(max_rotate=20, max_zoom=1.2,\n","    max_lighting=0.5, max_warp=0.5,\n","  )[0]\n","  return strong_transforms\n","\n","def get_extra_strong_transforms():\n","  custom_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.ToPILImage(),\n","    torchvision.transforms.RandomCrop(300, pad_if_needed=True, padding_mode=\"reflect\"),\n","    torchvision.transforms.Resize(train_image_size),\n","    torchvision.transforms.ColorJitter(0, 0, 0.9, 0.2),\n","    torchvision.transforms.ToTensor(),\n","    # torchvision.transforms.ToPILImage(),\n","  ])\n","  return custom_transforms"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7f6Tn95qLOf"},"source":[""],"execution_count":null,"outputs":[]}]}